{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27185,"status":"ok","timestamp":1652689339315,"user":{"displayName":"Ivan Aguilar","userId":"05805327091284749884"},"user_tz":-120},"id":"pr8zxnAdvMiA","outputId":"bea21880-3485-4099-f7c4-5271350b4df8"},"outputs":[],"source":["#from google.colab import drive\n","#drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19469,"status":"ok","timestamp":1652689358782,"user":{"displayName":"Ivan Aguilar","userId":"05805327091284749884"},"user_tz":-120},"id":"zn5U4EE6K86v","outputId":"504ed589-1db9-4abb-9c64-fbf7dfedc56c"},"outputs":[{"name":"stdout","output_type":"stream","text":["1.11.0+cpu\n"]}],"source":["# Install required packages.\n","import os\n","import torch\n","os.environ['TORCH'] = torch.__version__\n","print(torch.__version__)\n","\n","#!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n","#!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n","#!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":376,"status":"ok","timestamp":1652689359153,"user":{"displayName":"Ivan Aguilar","userId":"05805327091284749884"},"user_tz":-120},"id":"3_v_5lbjv1NP","outputId":"ed5ff6e7-7b06-4325-a651-3d7aae6f08d9"},"outputs":[{"name":"stdout","output_type":"stream","text":["cpu\n"]}],"source":["import torch\n","import pickle\n","import random\n","import numpy as np\n","import math\n","from torch_geometric.data import DenseDataLoader\n","\n","from torch.nn import Linear\n","import torch.nn.functional as F\n","from torch_geometric.nn import GATConv, BatchNorm, GraphNorm, GCNConv, DenseGraphConv\n","from torch_geometric.nn import global_mean_pool, dense_diff_pool, dense_mincut_pool\n","from torch_geometric.utils import to_dense_adj, to_dense_batch\n","from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n","\n","torch.cuda.is_available()\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"G43Ga8ocaFdS"},"outputs":[],"source":["with open(r'C:\\\\Users\\\\ivano\\\\Desktop\\\\DSMMaster\\\\CryptoThesis\\\\data\\\\address_subgraphs.pkl', \"rb\") as input_file:\n","    dataset = pickle.load(input_file)\n"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"mHSP6-RBOqCE"},"outputs":[{"name":"stdout","output_type":"stream","text":["====================\n","Number of graphs: 102077\n"]},{"ename":"AttributeError","evalue":"'list' object has no attribute 'data'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[1;32mc:\\Users\\ivano\\Desktop\\DSMMaster\\CryptoThesis\\graph_classification_diffpool.ipynb Cell 5'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ivano/Desktop/DSMMaster/CryptoThesis/graph_classification_diffpool.ipynb#ch0000004?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNumber of graphs: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(dataset)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ivano/Desktop/DSMMaster/CryptoThesis/graph_classification_diffpool.ipynb#ch0000004?line=3'>4</a>\u001b[0m data \u001b[39m=\u001b[39m dataset[\u001b[39m0\u001b[39m]  \u001b[39m# Get the first graph object.\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ivano/Desktop/DSMMaster/CryptoThesis/graph_classification_diffpool.ipynb#ch0000004?line=4'>5</a>\u001b[0m average_nodes \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(dataset\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39mx\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(dataset))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ivano/Desktop/DSMMaster/CryptoThesis/graph_classification_diffpool.ipynb#ch0000004?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ivano/Desktop/DSMMaster/CryptoThesis/graph_classification_diffpool.ipynb#ch0000004?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(data)\n","\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'data'"]}],"source":["print('====================')\n","print(f'Number of graphs: {len(dataset)}')\n","\n","data = dataset[0]  # Get the first graph object.\n","\n","print()\n","print(data)\n","print('=============================================================')\n","\n","# Gather some statistics about the first graph.\n","print(f'Number of nodes: {data.num_nodes}')\n","print(f'Number of edges: {data.num_edges}')\n","print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n","print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n","print(f'Has self-loops: {data.has_self_loops()}')\n","print(f'Is undirected: {data.is_undirected()}')"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"u63WREK2MSlA"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of high risk addresses: 10169\n","Number of safe addresses: 91579\n"]}],"source":["classes = {dataset[i].y.index.map(str)[0]: dataset[i].y.item() for i in range(len(dataset))}\n","classes_1 = dict(filter(lambda i: i[1] == 1, classes.items()))\n","classes_0 = dict(filter(lambda i: i[1] == 0, classes.items()))\n","\n","print(f'Number of high risk addresses: {len(classes_1.keys())}')\n","print(f'Number of safe addresses: {len(classes_0.keys())}')\n","\n","# Balance the high risk and safe addresses (undersampling safe addresses)\n","random.seed(1993)\n","sample_safe = random.sample(list(classes_0.keys()), k = len(classes_1.keys()))\n","\n","classes_0_trim = dict(filter(lambda i: i[0] in sample_safe, classes_0.items()))\n","classes_balanced = {**classes_1, **classes_0_trim}"]},{"cell_type":"markdown","metadata":{"id":"QYrzrQYJxnu8"},"source":["Need a way to get high risk graphs and then train against balanced number of licit graphs"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"j11WiUr-PRH_"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of training graphs: 16270\n","Number of testing graphs: 4068\n"]}],"source":["classes_balanced_keys = list(classes_balanced.keys())\n","train_share = 0.8\n","\n","train_keys = random.sample(classes_balanced_keys, k = round(train_share*len(classes_balanced_keys)))\n","test_keys = random.sample(classes_balanced_keys, k = len(classes_balanced_keys) - round(train_share*len(classes_balanced_keys)))\n","\n","train_dataset = [graph for graph in dataset if graph.y.index[0] in train_keys] \n","test_dataset = [graph for graph in dataset if graph.y.index[0] in test_keys]\n","\n","print(f'Number of training graphs: {len(train_dataset)}')\n","print(f'Number of testing graphs: {len(test_dataset)}')"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"kNF8ip-UtFrk"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\ivano\\AppData\\Local\\Temp\\ipykernel_14904\\3021064243.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  data.y = torch.tensor(data.y).type(torch.LongTensor)\n"]}],"source":["for data in train_dataset:\n","  data.y = torch.tensor(data.y).type(torch.LongTensor)\n","\n","for data in test_dataset:\n","  data.y = torch.tensor(data.y).type(torch.LongTensor) "]},{"cell_type":"code","execution_count":12,"metadata":{"id":"0gZ-l0npPIca"},"outputs":[{"data":{"text/plain":["\"\\nfor step, data in enumerate(train_loader):\\n    print(f'Step {step + 1}:')\\n    print('=======')\\n    print(f'Number of graphs in the current batch: {data.num_graphs}')\\n    print(data)\\n    print()\\n\""]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["from torch_geometric.loader import DataLoader\n","batch_size = 32\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n","'''\n","for step, data in enumerate(train_loader):\n","    print(f'Step {step + 1}:')\n","    print('=======')\n","    print(f'Number of graphs in the current batch: {data.num_graphs}')\n","    print(data)\n","    print()\n","'''"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":545,"status":"ok","timestamp":1652638448541,"user":{"displayName":"Ivan Aguilar","userId":"05805327091284749884"},"user_tz":-120},"id":"CN3sRVuaQ88l","outputId":"2aaffb91-975c-4310-cdd8-6a6d95f8e620"},"outputs":[],"source":["# GAT\n","\n","class GAT(torch.nn.Module):\n","    def __init__(self, hidden_channels, out_channels, heads, num_nodes):\n","        super(GAT, self).__init__()\n","        self.num_nodes = num_nodes\n","        #torch.manual_seed(12345)\n","        self.num_nodes = math.ceil(0.25 * self.num_nodes)\n","        self.gnn_pool_1 = GNN(18, hidden_channels, self.num_nodes)\n","        #self.gat_node_1 = GATConv(18, hidden_channels, edge_dim = 2, heads = heads)\n","        self.gnn_embed_1 = GNN(18, hidden_channels, hidden_channels)\n","\n","        self.num_nodes = math.ceil(0.25 * self.num_nodes)\n","        self.gnn_pool_2 = GNN(hidden_channels, hidden_channels, self.num_nodes)\n","        #self.gat_node_2 = GATConv(heads * hidden_channels, hidden_channels, edge_dim = 2, heads = heads)\n","        self.gnn_embed_2 = GNN(hidden_channels, hidden_channels, hidden_channels, lin=False)\n","\n","        #self.gat_node_3 = GATConv(heads * hidden_channels, out_channels, edge_dim = 2, heads = heads)\n","        self.gnn_embed_3 = GNN(hidden_channels, hidden_channels, hidden_channels, lin=False)\n","\n","        self.lin = Linear(out_channels * heads, 2)\n","        \n","        self.graphnorm1 = GraphNorm(hidden_channels * heads)\n","        self.graphnorm2 = GraphNorm(hidden_channels * heads)\n","        self.graphnorm3 = GraphNorm(out_channels * heads)\n","\n","    def forward(self, x, edge_index, edge_attr, batch):\n","        self.adj = to_dense_adj(edge_index)\n","        # 1. Obtain node embeddings \n","        x = x.float()\n","        print(x.shape)\n","        s = self.gnn_pool_1(x, edge_index, None)\n","        #x = self.gat_node_1(x, edge_index, edge_attr = edge_attr)\n","        x = self.gnn_embed_1(x, edge_index, None)\n","        #x = self.graphnorm1(x)\n","        #x = F.leaky_relu(x)\n","\n","        #x, self.adj, l1, e1 = dense_diff_pool(x, self.adj, s, None)\n","        #s = self.gnn_pool_2(x, edge_index, None)\n","        #x = self.gat_node_2(x, edge_index, edge_attr = edge_attr)\n","        #x = self.gnn_embed_2(x, edge_index, None)\n","        #x = self.graphnorm2(x)\n","\n","        #x = F.dropout(x, p=0.5, training=self.training)\n","        #x = F.leaky_relu(x)\n","        x, self.adj, l1, e1 = dense_diff_pool(x, self.adj, s, None)\n","\n","        #x = self.gat_node_3(x, edge_index, edge_attr = edge_attr)\n","        x = self.gnn_embed_3(x, self.adj, None)\n","        #x = self.graphnorm3(x)\n","        #x = F.dropout(x, p=0.5, training=self.training)\n","        #x = F.leaky_relu(x)\n","        \n","        x = x.mean(dim=1)\n","        # 2. Readout layer - turns node and edge embeddings into a graph embedding\n","        #x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n","\n","        # 3. Apply a final classifier\n","        x = self.lin(x)\n","        x = F.softmax(x, dim = 1)\n","        \n","        return x\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# DiffPool\n","\n","class GNN(torch.nn.Module):\n","    def __init__(self, in_channels, hidden_channels, out_channels, num_nodes_batch, normalize=False, lin=True):\n","        super(GNN, self).__init__()\n","        \n","        self.convs = torch.nn.ModuleList()\n","        self.bns = torch.nn.ModuleList()\n","        \n","        self.convs.append(GCNConv(in_channels, hidden_channels, normalize))\n","        self.bns.append(torch.nn.BatchNorm1d(num_nodes_batch))\n","        \n","        self.convs.append(GCNConv(hidden_channels, hidden_channels, normalize))\n","        self.bns.append(torch.nn.BatchNorm1d(num_nodes_batch))\n","        \n","        self.convs.append(GCNConv(hidden_channels, out_channels, normalize))\n","        self.bns.append(torch.nn.BatchNorm1d(num_nodes_batch))\n","\n","\n","    def forward(self, x, adj, mask=None):\n","        #batch_size, num_nodes, _ = x.size()\n","\n","        x = self.convs[0](x, adj)\n","        x = F.relu(x)\n","\n","        x = self.convs[1](x, adj, mask)\n","        x = F.relu(x)\n","\n","        x = self.convs[2](x, adj, mask)\n","        x = F.relu(x)\n","\n","        #for step in range(len(self.convs)): # iterate through the three convolutional steps\n","        #  print(f'step {step}')\n","        #  x = self.bns[step](F.relu(self.convs[step](x, adj, mask)))\n","\n","        return x\n","\n","class DiffPool(torch.nn.Module):\n","    def __init__(self):\n","        super(DiffPool, self).__init__()\n","        \n","        self.max_nodes = 0\n","        for data in dataset:\n","          temp_max = data.num_nodes\n","          if temp_max>self.max_nodes:\n","            self.max_nodes = temp_max\n","        \n","        self.max_nodes = 50\n","\n","        num_nodes_batch = self.max_nodes\n","        num_nodes = math.ceil(0.25 * self.max_nodes) \n","        self.gnn1_pool = GNN(18, 64, num_nodes, num_nodes_batch) \n","        self.gnn1_embed = GNN(18, 64, 64, num_nodes_batch)\n","\n","        num_nodes_batch = num_nodes\n","        num_nodes = math.ceil(0.25 * num_nodes)\n","\n","        self.gnn2_pool = GNN(64, 64, num_nodes, num_nodes_batch)\n","        self.gnn2_embed = GNN(64, 64, 64, num_nodes_batch, lin=False)\n","\n","        num_nodes_batch = num_nodes\n","        self.gnn3_embed = GNN(64, 64, 64, num_nodes_batch, lin=False)\n","\n","        self.lin1 = torch.nn.Linear(64, 64)\n","        self.lin2 = torch.nn.Linear(64, 32)\n","\n","    def forward(self, x, edge_index, batch, mask=None):\n","        \n","        s = self.gnn1_pool(x, edge_index)\n","        x = self.gnn1_embed(x, edge_index)\n","\n","        x, mask = to_dense_batch(x, batch)\n","        adj = to_dense_adj(edge_index, batch)\n","        \n","        x, adj, l1, e1 = dense_diff_pool(x, adj, s, mask)\n","        #x_1 = s_0.t() @ z_0\n","        #adj_1 = s_0.t() @ adj_0 @ s_0\n","        \n","        s = self.gnn2_pool(x, edge_index)\n","        x = self.gnn2_embed(x, edge_index)\n","\n","        x, adj, l2, e2 = dense_diff_pool(x, edge_index, s)\n","\n","        x = self.gnn3_embed(x, edge_index)\n","\n","        x = x.mean(dim=1)\n","        x = F.relu(self.lin1(x))\n","        x = self.lin2(x)\n","        return F.log_softmax(x, dim=-1), l1 + l2, e1 + e2"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["class Net(torch.nn.Module):\n","    def __init__(self, in_channels, out_channels, hidden_channels=32):\n","        super().__init__()\n","\n","        self.conv1 = GCNConv(in_channels, hidden_channels)\n","        num_nodes = math.ceil(0.5 * average_nodes)\n","        self.pool1 = Linear(hidden_channels, num_nodes)\n","\n","        self.conv2 = DenseGraphConv(hidden_channels, hidden_channels)\n","        num_nodes = math.ceil(0.5 * num_nodes)\n","        self.pool2 = Linear(hidden_channels, num_nodes)\n","\n","        self.conv3 = DenseGraphConv(hidden_channels, hidden_channels)\n","\n","        self.lin1 = Linear(hidden_channels, hidden_channels)\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","\n","    def forward(self, x, edge_index, batch):\n","        x = self.conv1(x, edge_index).relu()\n","\n","        x, mask = to_dense_batch(x, batch)\n","        adj = to_dense_adj(edge_index, batch)\n","\n","        s = self.pool1(x)\n","        x, adj, mc1, o1 = dense_mincut_pool(x, adj, s, mask)\n","\n","        x = self.conv2(x, adj).relu()\n","        s = self.pool2(x)\n","\n","        x, adj, mc2, o2 = dense_mincut_pool(x, adj, s)\n","\n","        x = self.conv3(x, adj)\n","\n","        x = x.mean(dim=1)\n","        x = self.lin1(x).relu()\n","        x = self.lin2(x)\n","        return F.log_softmax(x, dim=-1), mc1 + mc2, o1 + o2\n"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":["average_nodes = 0\n","\n","for data in dataset:\n","    average_nodes = average_nodes + int(data.x.size(0) / len(data))\n","\n","average_nodes = average_nodes / len(dataset)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","#model = GAT(hidden_channels = 128, out_channels = 32, heads = 10, num_nodes=150)\n","#model = DiffPool()\n","\n","model = Net(in_channels = 18, out_channels = 32).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","#print(model)"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"HvhgQoO8Svw4"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\ivano\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","C:\\Users\\ivano\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 000\n","Tr Acc: 0.503, Tr Rec: 0.000, Tr Pre: 0.000, Tr F1: 0.000Te Acc: 0.495, Te Rec: 0.000, Te Pre: 0.000, Te F1: 0.000\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\ivano\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","C:\\Users\\ivano\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","C:\\Users\\ivano\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","C:\\Users\\ivano\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","C:\\Users\\ivano\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","C:\\Users\\ivano\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","C:\\Users\\ivano\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","C:\\Users\\ivano\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","C:\\Users\\ivano\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","C:\\Users\\ivano\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32mc:\\Users\\ivano\\Desktop\\DSMMaster\\CryptoThesis\\graph_classification_diffpool.ipynb Cell 15'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ivano/Desktop/DSMMaster/CryptoThesis/graph_classification_diffpool.ipynb#ch0000013?line=39'>40</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ivano/Desktop/DSMMaster/CryptoThesis/graph_classification_diffpool.ipynb#ch0000013?line=40'>41</a>\u001b[0m     train()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ivano/Desktop/DSMMaster/CryptoThesis/graph_classification_diffpool.ipynb#ch0000013?line=41'>42</a>\u001b[0m     train_metrics \u001b[39m=\u001b[39m test(train_loader)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ivano/Desktop/DSMMaster/CryptoThesis/graph_classification_diffpool.ipynb#ch0000013?line=42'>43</a>\u001b[0m     test_metrics \u001b[39m=\u001b[39m test(test_loader)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ivano/Desktop/DSMMaster/CryptoThesis/graph_classification_diffpool.ipynb#ch0000013?line=44'>45</a>\u001b[0m     \u001b[39m#print(train_metrics)\u001b[39;00m\n","\u001b[1;32mc:\\Users\\ivano\\Desktop\\DSMMaster\\CryptoThesis\\graph_classification_diffpool.ipynb Cell 15'\u001b[0m in \u001b[0;36mtest\u001b[1;34m(loader)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ivano/Desktop/DSMMaster/CryptoThesis/graph_classification_diffpool.ipynb#ch0000013?line=25'>26</a>\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ivano/Desktop/DSMMaster/CryptoThesis/graph_classification_diffpool.ipynb#ch0000013?line=26'>27</a>\u001b[0m out, mc_loss, o_loss \u001b[39m=\u001b[39m model(data\u001b[39m.\u001b[39mx\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mfloat), data\u001b[39m.\u001b[39medge_index, data\u001b[39m.\u001b[39mbatch)  \n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ivano/Desktop/DSMMaster/CryptoThesis/graph_classification_diffpool.ipynb#ch0000013?line=27'>28</a>\u001b[0m pred \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39margmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mtolist()  \u001b[39m# Use the class with highest probability.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ivano/Desktop/DSMMaster/CryptoThesis/graph_classification_diffpool.ipynb#ch0000013?line=28'>29</a>\u001b[0m true \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39my\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ivano/Desktop/DSMMaster/CryptoThesis/graph_classification_diffpool.ipynb#ch0000013?line=29'>30</a>\u001b[0m correct \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(x \u001b[39m==\u001b[39m y \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(true, pred)) \u001b[39m# Check against ground-truth labels.\u001b[39;00m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import warnings\n","warnings.filterwarnings('ignore')\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","def train():\n","    model.train()\n","    for data in train_loader:  # Iterate in batches over the training dataset.\n","         data = data.to(device)\n","         optimizer.zero_grad()  # Clear gradients.\n","         out, mc_loss, o_loss = model(data.x.type(torch.float), data.edge_index, data.batch) \n","         loss = criterion(out, data.y)  # Compute the loss.\n","         loss.backward()  # Derive gradients.\n","         optimizer.step()  # Update parameters based on gradients.\n","\n","\n","def test(loader):\n","     model.eval()\n","        \n","     metrics = {\"accuracy\":0,\n","               \"precision\":0,\n","               \"recall\":0,\n","               \"f1_score\":0}\n","\n","     correct = 0\n","     actual, predicted = list(), list()\n","     for data in loader:  # Iterate in batches over the training/test dataset.\n","         data = data.to(device)\n","         out, mc_loss, o_loss = model(data.x.type(torch.float), data.edge_index, data.batch)  \n","         pred = out.cpu().argmax(dim=1).tolist()  # Use the class with highest probability.\n","         true = data.y.cpu().tolist()\n","         correct += sum(x == y for x, y in zip(true, pred)) # Check against ground-truth labels.\n","         actual += true\n","         predicted += pred \n","\n","     metrics['accuracy'] = correct / len(loader.dataset)\n","     metrics['precision'], metrics['recall'], metrics['f1_score'], _ = precision_recall_fscore_support(actual, predicted, average = 'binary') # precision, recall, f1score\n","     \n","     return metrics  # Derive ratio of correct predictions.\n","\n","epochs = 100\n","for epoch in range(epochs):\n","    train()\n","    train_metrics = test(train_loader)\n","    test_metrics = test(test_loader)\n","\n","    #print(train_metrics)\n","    if epoch%10==0  or epoch==epochs:\n","      print(f'Epoch: {epoch:03d}') \n","      print(f'Tr Acc: {train_metrics[\"accuracy\"]:.3f}, Tr Rec: {train_metrics[\"recall\"]:.3f}, Tr Pre: {train_metrics[\"precision\"]:.3f}, Tr F1: {train_metrics[\"f1_score\"]:.3f} '\n","            f'Te Acc: {test_metrics[\"accuracy\"]:.3f}, Te Rec: {test_metrics[\"recall\"]:.3f}, Te Pre: {test_metrics[\"precision\"]:.3f}, Te F1: {test_metrics[\"f1_score\"]:.3f}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Graph Classification_IA.ipynb","provenance":[{"file_id":"1QYGmp2kDpezaMPpgx8tLW9trOGdJYvGn","timestamp":1652098155637},{"file_id":"1I8a0DfQ3fI7Njc62__mVXUlcAleUclnb","timestamp":1651757841002}]},"interpreter":{"hash":"c09dffd9390eb6dd651821c8eba1c4865319b367747d0473c0369ffb39ae3dcc"},"kernelspec":{"display_name":"Python 3.9.12 64-bit (windows store)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}
