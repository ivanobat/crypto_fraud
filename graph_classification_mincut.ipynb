{"cells":[{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1999,"status":"ok","timestamp":1652807895099,"user":{"displayName":"Ivan Aguilar","userId":"05805327091284749884"},"user_tz":-120},"id":"pr8zxnAdvMiA","outputId":"628c4b78-f2d9-4088-e7f5-5e3634e97547"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12091,"status":"ok","timestamp":1652807907183,"user":{"displayName":"Ivan Aguilar","userId":"05805327091284749884"},"user_tz":-120},"id":"zn5U4EE6K86v","outputId":"52bbb62d-bf74-48dd-d0c3-f5c7a04315bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["1.11.0+cu113\n"]}],"source":["# Install required packages.\n","import os\n","import torch\n","os.environ['TORCH'] = torch.__version__\n","print(torch.__version__)\n","\n","!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n","!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1652807907489,"user":{"displayName":"Ivan Aguilar","userId":"05805327091284749884"},"user_tz":-120},"id":"3_v_5lbjv1NP","outputId":"e97354e3-fc5c-4d7d-8cc1-e98dc7a456c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}],"source":["import torch\n","import pickle\n","import random\n","import numpy as np\n","import math\n","from torch_geometric.data import DenseDataLoader\n","\n","from torch.nn import Linear\n","import torch.nn.functional as F\n","from torch_geometric.nn import GATConv, BatchNorm, GraphNorm, GCNConv, DenseGraphConv, DenseSAGEConv\n","from torch_geometric.nn import global_mean_pool, dense_diff_pool, dense_mincut_pool\n","from torch_geometric.utils import to_dense_adj, to_dense_batch\n","from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n","\n","torch.cuda.is_available()\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"G43Ga8ocaFdS","executionInfo":{"status":"ok","timestamp":1652808027652,"user_tz":-120,"elapsed":120165,"user":{"displayName":"Ivan Aguilar","userId":"05805327091284749884"}}},"outputs":[],"source":["with open(r'/content/drive/MyDrive/Augmented_Elliptic/address_level/address_subgraphs.pkl', \"rb\") as input_file:\n","    dataset = pickle.load(input_file)\n"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"mHSP6-RBOqCE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652808027653,"user_tz":-120,"elapsed":9,"user":{"displayName":"Ivan Aguilar","userId":"05805327091284749884"}},"outputId":"33e488ba-078b-4b0b-d017-9eb20d5c35d9"},"outputs":[{"output_type":"stream","name":"stdout","text":["====================\n","Number of graphs: 102077\n","\n","Data(edge_index=[2, 6060], interactions=[6060], num_nodes=98, x=[98, 25], y=node\n","2397173837    0\n","Name: class, dtype: int64, edge_attr=[6060, 5])\n","=============================================================\n","Number of nodes: 98\n","Number of edges: 6060\n","Average node degree: 61.84\n","Has isolated nodes: False\n","Has self-loops: True\n","Is undirected: False\n"]}],"source":["print('====================')\n","print(f'Number of graphs: {len(dataset)}')\n","\n","data = dataset[0]  # Get the first graph object.\n","\n","print()\n","print(data)\n","print('=============================================================')\n","\n","# Gather some statistics about the first graph.\n","print(f'Number of nodes: {data.num_nodes}')\n","print(f'Number of edges: {data.num_edges}')\n","print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n","print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n","print(f'Has self-loops: {data.has_self_loops()}')\n","print(f'Is undirected: {data.is_undirected()}')"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"u63WREK2MSlA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652808098939,"user_tz":-120,"elapsed":71293,"user":{"displayName":"Ivan Aguilar","userId":"05805327091284749884"}},"outputId":"cddde676-fc86-4f5d-85d0-885d039efb38"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of high risk addresses: 10169\n","Number of safe addresses: 91579\n"]}],"source":["classes = {dataset[i].y.index.map(str)[0]: dataset[i].y.item() for i in range(len(dataset))}\n","classes_1 = dict(filter(lambda i: i[1] == 1, classes.items()))\n","classes_0 = dict(filter(lambda i: i[1] == 0, classes.items()))\n","\n","print(f'Number of high risk addresses: {len(classes_1.keys())}')\n","print(f'Number of safe addresses: {len(classes_0.keys())}')\n","\n","# Balance the high risk and safe addresses (undersampling safe addresses)\n","random.seed(1993)\n","sample_safe = random.sample(list(classes_0.keys()), k = len(classes_1.keys()))\n","\n","classes_0_trim = dict(filter(lambda i: i[0] in sample_safe, classes_0.items()))\n","classes_balanced = {**classes_1, **classes_0_trim}"]},{"cell_type":"markdown","metadata":{"id":"QYrzrQYJxnu8"},"source":["Need a way to get high risk graphs and then train against balanced number of licit graphs"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"j11WiUr-PRH_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652808225058,"user_tz":-120,"elapsed":126137,"user":{"displayName":"Ivan Aguilar","userId":"05805327091284749884"}},"outputId":"18a7867c-7aa5-45cf-f58d-e8c2a7fbdf17"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of training graphs: 16270\n","Number of testing graphs: 4068\n"]}],"source":["classes_balanced_keys = list(classes_balanced.keys())\n","train_share = 0.8\n","\n","train_keys = random.sample(classes_balanced_keys, k = round(train_share*len(classes_balanced_keys)))\n","test_keys = random.sample(classes_balanced_keys, k = len(classes_balanced_keys) - round(train_share*len(classes_balanced_keys)))\n","\n","train_dataset = [graph for graph in dataset if graph.y.index[0] in train_keys] \n","test_dataset = [graph for graph in dataset if graph.y.index[0] in test_keys]\n","\n","print(f'Number of training graphs: {len(train_dataset)}')\n","print(f'Number of testing graphs: {len(test_dataset)}')"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"kNF8ip-UtFrk","executionInfo":{"status":"ok","timestamp":1652808226628,"user_tz":-120,"elapsed":1587,"user":{"displayName":"Ivan Aguilar","userId":"05805327091284749884"}}},"outputs":[],"source":["for data in train_dataset:\n","  data.y = torch.tensor(data.y).type(torch.LongTensor)\n","\n","for data in test_dataset:\n","  data.y = torch.tensor(data.y).type(torch.LongTensor) "]},{"cell_type":"code","execution_count":42,"metadata":{"id":"0gZ-l0npPIca","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1652808226629,"user_tz":-120,"elapsed":9,"user":{"displayName":"Ivan Aguilar","userId":"05805327091284749884"}},"outputId":"4aed5041-a358-4fa8-9565-0d9fdde405a0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\nfor step, data in enumerate(train_loader):\\n    print(f'Step {step + 1}:')\\n    print('=======')\\n    print(f'Number of graphs in the current batch: {data.num_graphs}')\\n    print(data)\\n    print()\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":42}],"source":["from torch_geometric.loader import DataLoader\n","batch_size = 32\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n","'''\n","for step, data in enumerate(train_loader):\n","    print(f'Step {step + 1}:')\n","    print('=======')\n","    print(f'Number of graphs in the current batch: {data.num_graphs}')\n","    print(data)\n","    print()\n","'''"]},{"cell_type":"code","execution_count":43,"metadata":{"executionInfo":{"elapsed":311,"status":"ok","timestamp":1652808227346,"user":{"displayName":"Ivan Aguilar","userId":"05805327091284749884"},"user_tz":-120},"id":"CN3sRVuaQ88l"},"outputs":[],"source":["# GAT\n","\n","class GAT(torch.nn.Module):\n","    def __init__(self, hidden_channels, out_channels, heads):\n","        super(GAT, self).__init__()\n","        torch.manual_seed(12345)\n","        self.gat_node_1 = GATConv(18, hidden_channels, edge_dim = 2, heads = heads)\n","        self.gat_node_2 = GATConv(heads * hidden_channels, hidden_channels, edge_dim = 2, heads = heads)\n","        self.gat_node_3 = GATConv(heads * hidden_channels, out_channels, edge_dim = 2, heads = heads)\n","\n","        self.lin = Linear(out_channels * heads, 2)\n","        \n","        self.graphnorm1 = GraphNorm(hidden_channels * heads)\n","        self.graphnorm2 = GraphNorm(hidden_channels * heads)\n","        self.graphnorm3 = GraphNorm(out_channels * heads)\n","\n","    def forward(self, x, edge_index, edge_attr, batch):\n","        # 1. Obtain node embeddings \n","        x = x.float()\n","        x = self.gat_node_1(x, edge_index, edge_attr = edge_attr)\n","        x = self.graphnorm1(x)\n","        x = F.leaky_relu(x)\n","        x = self.gat_node_2(x, edge_index, edge_attr = edge_attr)\n","        x = self.graphnorm2(x)\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = F.leaky_relu(x)\n","        x = self.gat_node_3(x, edge_index, edge_attr = edge_attr)\n","        x = self.graphnorm3(x)\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = F.leaky_relu(x)\n","\n","        # 2. Readout layer - turns node and edge embeddings into a graph embedding\n","        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n","\n","        # 3. Apply a final classifier\n","        x = self.lin(x)\n","        x = F.softmax(x, dim = 1)\n","        \n","        return x\n","\n"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"UdjmtDlPaAij","executionInfo":{"status":"ok","timestamp":1652808227346,"user_tz":-120,"elapsed":6,"user":{"displayName":"Ivan Aguilar","userId":"05805327091284749884"}}},"outputs":[],"source":["# DiffPool\n","\n","class GNN(torch.nn.Module):\n","    def __init__(self, in_channels, hidden_channels, out_channels, normalize=False, lin=True):\n","        super().__init__()\n","\n","        self.conv1 = DenseSAGEConv(in_channels, hidden_channels, normalize)\n","        self.bn1 = GraphNorm(hidden_channels)\n","        self.conv2 = DenseSAGEConv(hidden_channels, hidden_channels, normalize)\n","        self.bn2 = GraphNorm(hidden_channels)\n","        self.conv3 = DenseSAGEConv(hidden_channels, out_channels, normalize)\n","        self.bn3 = GraphNorm(out_channels)\n","\n","        if lin is True:\n","            self.lin = torch.nn.Linear(2 * hidden_channels + out_channels,\n","                                       out_channels)\n","        else:\n","            self.lin = None\n","\n","    def bn(self, i, x):\n","        batch_size, num_nodes, num_channels = x.size()\n","\n","        x = x.view(-1, num_channels)\n","        x = getattr(self, f'bn{i}')(x)\n","        x = x.view(batch_size, num_nodes, num_channels)\n","        return x\n","\n","    def forward(self, x, adj, batch, mask=None):\n","        #batch_size, num_nodes, in_channels = x.size()\n","\n","        x0 = x\n","\n","        adj_dense = to_dense_adj(adj, batch)\n","        \n","        x1 = self.bn(1, self.conv1(x0, adj, mask).relu())\n","        x2 = self.bn(2, self.conv2(x1, adj, mask).relu())\n","        x3 = self.bn(3, self.conv3(x2, adj, mask).relu())\n","\n","        x = torch.cat([x1, x2, x3], dim=-1)\n","\n","        if self.lin is not None:\n","            x = self.lin(x).relu()\n","\n","        return x\n","\n","\n","class DiffPool(torch.nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.max_nodes = 0\n","        for data in dataset:\n","          temp_max = data.num_nodes\n","          if temp_max>self.max_nodes:\n","            self.max_nodes = temp_max\n","\n","        num_nodes = math.ceil(0.25 * self.max_nodes)\n","        self.gnn1_pool = GNN(18, 64, num_nodes)\n","        self.gnn1_embed = GNN(18, 64, 64, lin=False)\n","\n","        num_nodes = math.ceil(0.25 * num_nodes)\n","        self.gnn2_pool = GNN(3 * 64, 64, num_nodes)\n","        self.gnn2_embed = GNN(3 * 64, 64, 64, lin=False)\n","\n","        self.gnn3_embed = GNN(3 * 64, 64, 64, lin=False)\n","\n","        self.lin1 = torch.nn.Linear(3 * 64, 64)\n","        self.lin2 = torch.nn.Linear(64, 2)\n","\n","    def forward(self, x, adj, batch, mask=None):\n","        \n","        s = self.gnn1_pool(x, adj, mask)\n","        x = self.gnn1_embed(x, adj, mask)\n","\n","        #x, mask = to_dense_batch(x, batch)\n","        adj = to_dense_adj(adj, batch)\n","\n","        x, adj, l1, e1 = dense_diff_pool(x, adj, s, mask)\n","\n","        s = self.gnn2_pool(x, adj)\n","        x = self.gnn2_embed(x, adj)\n","\n","        x, adj, l2, e2 = dense_diff_pool(x, adj, s)\n","\n","        x = self.gnn3_embed(x, adj)\n","\n","        x = x.mean(dim=1)\n","        x = self.lin1(x).relu()\n","        x = self.lin2(x)\n","        return F.log_softmax(x, dim=-1), l1 + l2, e1 + e2"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"w3Tp8IU_aAik","executionInfo":{"status":"ok","timestamp":1652808227347,"user_tz":-120,"elapsed":6,"user":{"displayName":"Ivan Aguilar","userId":"05805327091284749884"}}},"outputs":[],"source":["# MinCut\n","class MinCut(torch.nn.Module):\n","    def __init__(self, in_channels, out_channels, hidden_channels=32):\n","        super().__init__()\n","\n","        self.conv1 = GCNConv(in_channels, hidden_channels)\n","        num_nodes = math.ceil(0.5 * average_nodes)\n","        self.pool1 = Linear(hidden_channels, num_nodes)\n","\n","        self.conv2 = DenseGraphConv(hidden_channels, hidden_channels)\n","        num_nodes = math.ceil(0.5 * num_nodes)\n","        self.pool2 = Linear(hidden_channels, num_nodes)\n","\n","        self.conv3 = DenseGraphConv(hidden_channels, hidden_channels)\n","\n","        self.lin1 = Linear(hidden_channels, hidden_channels)\n","        self.lin2 = Linear(hidden_channels, out_channels)\n","\n","    def forward(self, x, edge_index, batch):\n","        x = self.conv1(x, edge_index).relu()\n","\n","        x, mask = to_dense_batch(x, batch)\n","        adj = to_dense_adj(edge_index, batch)\n","\n","        s = self.pool1(x)\n","        x, adj, mc1, o1 = dense_mincut_pool(x, adj, s, mask)\n","\n","        x = self.conv2(x, adj).relu()\n","        s = self.pool2(x)\n","\n","        x, adj, mc2, o2 = dense_mincut_pool(x, adj, s)\n","\n","        x = self.conv3(x, adj)\n","\n","        x = x.mean(dim=1)\n","        x = self.lin1(x).relu()\n","        x = self.lin2(x)\n","        return F.log_softmax(x, dim=-1), mc1 + mc2, o1 + o2\n"]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"soSHT1NjaAil","executionInfo":{"status":"ok","timestamp":1652808795026,"user_tz":-120,"elapsed":1159,"user":{"displayName":"Ivan Aguilar","userId":"05805327091284749884"}},"outputId":"5bb58bc5-774e-4711-948f-87c556d00927"},"outputs":[{"output_type":"stream","name":"stdout","text":["MinCut(\n","  (conv1): GCNConv(25, 256)\n","  (pool1): Linear(in_features=256, out_features=1000, bias=True)\n","  (conv2): DenseGraphConv(256, 256)\n","  (pool2): Linear(in_features=256, out_features=500, bias=True)\n","  (conv3): DenseGraphConv(256, 256)\n","  (lin1): Linear(in_features=256, out_features=256, bias=True)\n","  (lin2): Linear(in_features=256, out_features=2, bias=True)\n",")\n"]}],"source":["average_nodes = 0\n","\n","for data in dataset:\n","    average_nodes = average_nodes + int(data.x.size(0) / len(data))\n","\n","average_nodes = average_nodes / len(dataset)\n","print(average_nodes)\n","average_nodes = 2000\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","#model = GAT(hidden_channels = 128, out_channels = 32, heads = 10).to(device)\n","#model = DiffPool().to(device)\n","model = MinCut(in_channels = 25, hidden_channels = 256, out_channels = 2).to(device)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-4)\n","print(model)"]},{"cell_type":"code","execution_count":52,"metadata":{"id":"HvhgQoO8Svw4","colab":{"base_uri":"https://localhost:8080/","height":797},"executionInfo":{"status":"error","timestamp":1652810444614,"user_tz":-120,"elapsed":1645893,"user":{"displayName":"Ivan Aguilar","userId":"05805327091284749884"}},"outputId":"21ad57e8-cc5a-4f67-cde6-6beeeda278f0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 000\n","Tr Acc: 0.629, Tr Rec: 0.564, Tr Pre: 0.647, Tr F1: 0.603 Te Acc: 0.628, Te Rec: 0.576, Te Pre: 0.668, Te F1: 0.619\n","Epoch: 001\n","Tr Acc: 0.701, Tr Rec: 0.737, Tr Pre: 0.686, Tr F1: 0.711 Te Acc: 0.703, Te Rec: 0.746, Te Pre: 0.704, Te F1: 0.724\n","Epoch: 002\n","Tr Acc: 0.643, Tr Rec: 0.710, Tr Pre: 0.625, Tr F1: 0.665 Te Acc: 0.644, Te Rec: 0.709, Te Pre: 0.645, Te F1: 0.676\n","Epoch: 003\n","Tr Acc: 0.715, Tr Rec: 0.805, Tr Pre: 0.681, Tr F1: 0.738 Te Acc: 0.724, Te Rec: 0.816, Te Pre: 0.704, Te F1: 0.756\n","Epoch: 004\n","Tr Acc: 0.742, Tr Rec: 0.697, Tr Pre: 0.765, Tr F1: 0.730 Te Acc: 0.749, Te Rec: 0.711, Te Pre: 0.788, Te F1: 0.747\n","Epoch: 005\n","Tr Acc: 0.742, Tr Rec: 0.790, Tr Pre: 0.720, Tr F1: 0.753 Te Acc: 0.741, Te Rec: 0.787, Te Pre: 0.736, Te F1: 0.761\n","Epoch: 006\n","Tr Acc: 0.720, Tr Rec: 0.625, Tr Pre: 0.770, Tr F1: 0.690 Te Acc: 0.711, Te Rec: 0.626, Te Pre: 0.778, Te F1: 0.694\n","Epoch: 007\n","Tr Acc: 0.746, Tr Rec: 0.783, Tr Pre: 0.728, Tr F1: 0.755 Te Acc: 0.752, Te Rec: 0.791, Te Pre: 0.749, Te F1: 0.769\n","Epoch: 008\n","Tr Acc: 0.759, Tr Rec: 0.774, Tr Pre: 0.751, Tr F1: 0.762 Te Acc: 0.763, Te Rec: 0.782, Te Pre: 0.768, Te F1: 0.775\n","Epoch: 009\n","Tr Acc: 0.738, Tr Rec: 0.752, Tr Pre: 0.730, Tr F1: 0.741 Te Acc: 0.735, Te Rec: 0.751, Te Pre: 0.746, Te F1: 0.748\n","Epoch: 010\n","Tr Acc: 0.745, Tr Rec: 0.803, Tr Pre: 0.718, Tr F1: 0.759 Te Acc: 0.745, Te Rec: 0.798, Te Pre: 0.736, Te F1: 0.766\n","Epoch: 011\n","Tr Acc: 0.720, Tr Rec: 0.768, Tr Pre: 0.699, Tr F1: 0.732 Te Acc: 0.722, Te Rec: 0.771, Te Pre: 0.718, Te F1: 0.744\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-52-4657c9699a4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mtrain_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mtest_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m#print(train_metrics)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-52-4657c9699a4a>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m     37\u001b[0m          \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m          \u001b[0;31m#out = model(data.x, data.edge_index, data.edge_attr, data.batch) # GAT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m          \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmc_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# MinCutPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m          \u001b[0;31m#out = model(data.x.type(torch.float), data.edge_index, data.batch) # DiffPool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m          \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Use the class with highest probability.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-45-0fc8e6b94028>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, batch)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdense_mincut_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/nn/dense/mincut_pool.py\u001b[0m in \u001b[0;36mdense_mincut_pool\u001b[0;34m(x, adj, s, mask)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;31m# Orthogonality regularization.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mi_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     ortho_loss = torch.norm(\n\u001b[1;32m     83\u001b[0m         \u001b[0mss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import warnings\n","warnings.filterwarnings('ignore')\n","\n","#optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","#criterion = torch.nn.CrossEntropyLoss()\n","\n","def train():\n","    model.train()\n","    for data in train_loader:  # Iterate in batches over the training dataset.\n","         data = data.to(device)\n","         #print(data)\n","         #data.x = data.x.view(, data.num_nodes, 1)\n","         data.y = data.y.type(torch.LongTensor).to(device)\n","         optimizer.zero_grad()  # Clear gradients.\n","         #out = model(data.x, data.edge_index, data.edge_attr, data.batch) # GAT\n","         out, mc_loss, o_loss = model(data.x.type(torch.float), data.edge_index, data.batch) # MinCutPool\n","         #out = model(data.x.type(torch.float), data.edge_index, data.batch) # DiffPool\n","         #loss = criterion(out, data.y)  # Compute the loss.\n","         loss = F.nll_loss(out, data.y.view(-1)) + mc_loss + o_loss\n","         loss.backward()  # Derive gradients.\n","         optimizer.step()  # Update parameters based on gradients.\n","\n","\n","def test(loader):\n","     model.eval()\n","        \n","     metrics = {\"accuracy\":0,\n","               \"precision\":0,\n","               \"recall\":0,\n","               \"f1_score\":0}\n","\n","     correct = 0\n","     actual, predicted = list(), list()\n","     for data in loader:  # Iterate in batches over the training/test dataset.\n","         data = data.to(device)\n","         \n","         data.y = data.y.type(torch.LongTensor).to(device)\n","         #out = model(data.x, data.edge_index, data.edge_attr, data.batch) # GAT\n","         out, mc_loss, o_loss = model(data.x.type(torch.float), data.edge_index, data.batch) # MinCutPool\n","         #out = model(data.x.type(torch.float), data.edge_index, data.batch) # DiffPool\n","         pred = out.cpu().argmax(dim=1).tolist()  # Use the class with highest probability.\n","         true = data.y.cpu().tolist()\n","         correct += sum(x == y for x, y in zip(true, pred)) # Check against ground-truth labels.\n","         actual += true\n","         predicted += pred \n","\n","     metrics['accuracy'] = correct / len(loader.dataset)\n","     metrics['precision'], metrics['recall'], metrics['f1_score'], _ = precision_recall_fscore_support(actual, predicted, average = 'binary') # precision, recall, f1score\n","     \n","     return metrics  # Derive ratio of correct predictions.\n","\n","epochs = 100\n","for epoch in range(epochs):\n","    train()\n","    train_metrics = test(train_loader)\n","    test_metrics = test(test_loader)\n","\n","    #print(train_metrics)\n","    #if epoch%10==0  or epoch==epochs:\n","    print(f'Epoch: {epoch:03d}') \n","    print(f'Tr Acc: {train_metrics[\"accuracy\"]:.3f}, Tr Rec: {train_metrics[\"recall\"]:.3f}, Tr Pre: {train_metrics[\"precision\"]:.3f}, Tr F1: {train_metrics[\"f1_score\"]:.3f} '\n","            f'Te Acc: {test_metrics[\"accuracy\"]:.3f}, Te Rec: {test_metrics[\"recall\"]:.3f}, Te Pre: {test_metrics[\"precision\"]:.3f}, Te F1: {test_metrics[\"f1_score\"]:.3f}')"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"graph_classification_mincut.ipynb","provenance":[{"file_id":"1QYGmp2kDpezaMPpgx8tLW9trOGdJYvGn","timestamp":1652098155637},{"file_id":"1I8a0DfQ3fI7Njc62__mVXUlcAleUclnb","timestamp":1651757841002}]},"interpreter":{"hash":"c09dffd9390eb6dd651821c8eba1c4865319b367747d0473c0369ffb39ae3dcc"},"kernelspec":{"display_name":"Python 3.9.12 64-bit (windows store)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}